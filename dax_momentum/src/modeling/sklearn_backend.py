"""Utilities for running a scikit-learn baseline without PyTorch.

This module mirrors a subset of the PyTorch training pipeline so users can
train and evaluate the model with only ``scikit-learn`` installed.  It powers
the standalone ``pipeline.run_train_sklearn`` entry point and can also be
imported directly by other tooling if desired.
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List

import numpy as np
import pandas as pd
from loguru import logger
from sklearn.linear_model import Ridge
from sklearn.model_selection import TimeSeriesSplit
from joblib import dump

from features.scaler import save_scaler
from modeling.metrics import mae_np, mse_np, r2_score_np


@dataclass
class SklearnArtifacts:
    """Artifacts generated by the sklearn fallback training routine."""

    model_path: Path
    predictions_path: Path
    scaler_path: Path
    cv_report_path: Path | None
    metrics: Dict[str, float]


def _flatten_sequences(X: np.ndarray) -> np.ndarray:
    """Flatten ``(N, T, F)`` sequences to ``(N, T*F)`` feature matrices."""

    if X.ndim != 3:
        raise ValueError(
            "Expected sequences shaped (n_samples, time_steps, n_features)"
        )
    return X.reshape(X.shape[0], -1)


def _time_series_cv(
    X: np.ndarray,
    y: np.ndarray,
    n_splits: int,
    *,
    alpha: float,
) -> List[Dict[str, float]]:
    """Run simple time-series cross validation using a Ridge regressor."""

    splitter = TimeSeriesSplit(n_splits=n_splits)
    results: List[Dict[str, float]] = []

    for fold, (train_idx, val_idx) in enumerate(splitter.split(X), start=1):
        model = Ridge(alpha=alpha)
        model.fit(X[train_idx], y[train_idx])
        y_pred = model.predict(X[val_idx])
        metrics = {
            "fold": fold,
            "r2": r2_score_np(y[val_idx], y_pred),
            "mse": mse_np(y[val_idx], y_pred),
            "mae": mae_np(y[val_idx], y_pred),
        }
        logger.info("Sklearn CV fold %d metrics: %s", fold, metrics)
        results.append(metrics)

    return results


def _save_cv_report(results: List[Dict[str, float]], path: Path) -> None:
    """Persist cross-validation metrics to ``path`` in JSON format."""

    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as handle:
        json.dump(results, handle, indent=2)
    logger.info("Saved sklearn CV report to %s", path)


def train_sklearn_model(
    X_train: np.ndarray,
    y_train: np.ndarray,
    X_test: np.ndarray,
    y_test: np.ndarray,
    *,
    config: Dict[str, Any],
    train_df: pd.DataFrame,
    test_df: pd.DataFrame,
    time_steps: int,
    scaler: Any,
) -> SklearnArtifacts:
    """Train a Ridge regressor and persist the usual pipeline artifacts."""

    sklearn_cfg = config.get("sklearn", {}) if isinstance(config, dict) else {}
    alpha = float(sklearn_cfg.get("ridge_alpha", 1.0))

    X_train_flat = _flatten_sequences(X_train)
    X_test_flat = _flatten_sequences(X_test)

    cv_path: Path | None = None
    cv_config = config.get("cv", {}) if isinstance(config, dict) else {}
    n_splits = int(cv_config.get("n_splits", 0)) if cv_config else 0
    paths = config.get("paths", {}) if isinstance(config, dict) else {}
    if n_splits > 1:
        cv_results = _time_series_cv(X_train_flat, y_train, n_splits, alpha=alpha)
        cv_path = Path(paths.get("cv_report", "artifacts/cv_metrics.json"))
        _save_cv_report(cv_results, cv_path)

    model = Ridge(alpha=alpha)
    model.fit(X_train_flat, y_train)
    y_pred = model.predict(X_test_flat)

    metrics = {
        "r2": r2_score_np(y_test, y_pred),
        "mse": mse_np(y_test, y_pred),
        "mae": mae_np(y_test, y_pred),
    }
    logger.info("Sklearn fallback metrics: %s", metrics)

    scaler_path = Path(paths.get("scaler", "artifacts/scaler.pkl"))
    save_scaler(scaler, scaler_path)
    logger.info("Saved scaler to %s", scaler_path)

    model_path = Path(paths.get("model", "models/model.joblib")).with_suffix(
        ".joblib"
    )
    model_path.parent.mkdir(parents=True, exist_ok=True)
    dump(model, model_path)
    logger.info("Saved sklearn model to %s", model_path)

    predictions_path = Path(paths.get("predictions", "artifacts/predictions.csv"))
    predictions_path.parent.mkdir(parents=True, exist_ok=True)
    timestamps = (
        test_df.sort_values(["ric", "ts"])["ts"]
        .iloc[time_steps - 1 : time_steps - 1 + len(y_test)]
        .reset_index(drop=True)
    )
    pd.DataFrame(
        {
            "ts": timestamps,
            "y_true": y_test,
            "y_pred": y_pred,
        }
    ).to_csv(predictions_path, index=False)
    logger.info("Saved sklearn predictions to %s", predictions_path)

    return SklearnArtifacts(
        model_path=model_path,
        predictions_path=predictions_path,
        scaler_path=scaler_path,
        cv_report_path=cv_path,
        metrics=metrics,
    )

